{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define UNet Architecture\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "        super(UpBlock, self).__init__()\n",
    "        if up_sample_mode == 'conv_transpose':\n",
    "            self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)        \n",
    "        elif up_sample_mode == 'bilinear':\n",
    "            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported `up_sample_mode` (can take one of `conv_transpose` or `bilinear`)\")\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, down_input, skip_input):\n",
    "        x = self.up_sample(down_input)\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, out_classes=2, up_sample_mode='conv_transpose'):\n",
    "        super(UNet, self).__init__()\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128, self.up_sample_mode)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip1_out = self.down_conv1(x)\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        x = self.conv_last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Training Model with Train/Valid Data\n",
    "\n",
    "# Create the 4 layered UNet model\n",
    "model = UNet()\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import segmentation_models_pytorch.utils.metrics\n",
    "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
    "TRAINING = True\n",
    "\n",
    "# Set num of epochs\n",
    "EPOCHS = 12\n",
    "\n",
    "# Set device: `cuda` or `cpu`\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define loss function\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "# define metrics\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.00008),\n",
    "])\n",
    "\n",
    "# define learning rate scheduler (not used in this NB)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
    ")\n",
    "\n",
    "# load best saved model checkpoint from previous commit (if present)\n",
    "if os.path.exists('../input/unet-for-building-segmentation-pytorch/best_model.pth'):\n",
    "    model = torch.load('../input/unet-for-building-segmentation-pytorch/best_model.pth', map_location=DEVICE)\n",
    "\n",
    "# train and valid epochs\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "%%time\n",
    "\n",
    "if TRAINING:\n",
    "\n",
    "    best_iou_score = 0.0 # current best iou score\n",
    "    train_logs_list, valid_logs_list = [], [] # train and valid logs\n",
    "\n",
    "    for i in range(0, EPOCHS):\n",
    "\n",
    "        # Perform training & validation\n",
    "        print('\\nEpoch: {}'.format(i))\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "        train_logs_list.append(train_logs)\n",
    "        valid_logs_list.append(valid_logs)\n",
    "\n",
    "        # Save model if a better val IoU score is obtained\n",
    "        if best_iou_score < valid_logs['iou_score']:\n",
    "            best_iou_score = valid_logs['iou_score']\n",
    "            torch.save(model, '/content/gdrive/MyDrive/catracking/best_model.pth')\n",
    "            print('Model saved!')\n",
    "\n",
    "## Using Model to Perform Segmentation on Test Data\n",
    "\n",
    "# load model\n",
    "best_model = torch.load('/content/gdrive/MyDrive/catracking/best_model.pth', map_location=DEVICE)\n",
    "print('Loaded UNet model')\n",
    "\n",
    "class_rgb_values\n",
    "\n",
    "# create test dataloader to be used with UNet model (with preprocessing operation: to_tensor(...))\n",
    "test_dataset = CaImagesDataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn=None),   \n",
    "    class_rgb_values=class_rgb_values,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "# test dataset for visualization (without preprocessing transformations)\n",
    "test_dataset_vis = CaImagesDataset(\n",
    "    x_test_dir, y_test_dir, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    class_rgb_values=class_rgb_values,\n",
    ")\n",
    "\n",
    "# get a random test image/mask index\n",
    "random_idx = random.randint(0, len(test_dataset_vis)-1)\n",
    "image, mask = test_dataset_vis[random_idx]\n",
    "\n",
    "visualize(\n",
    "    original_image = image,\n",
    "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), class_rgb_values),\n",
    "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
    ")\n",
    "\n",
    "# Notice the images / masks are 1536*1536 because of 18px padding on all sides. \n",
    "# This is to ensure the input image dimensions to UNet model are a multiple of 2 (to account for pooling & transpose conv. operations).\n",
    "\n",
    "sample_preds_folder = '/content/gdrive/MyDrive/catracking/sample_predictions/'\n",
    "if not os.path.exists(sample_preds_folder):\n",
    "    os.makedirs(sample_preds_folder)\n",
    "\n",
    "# Center crop padded image / mask to original image dims\n",
    "def crop_image(image, target_image_dims=[1500,1500,3]):\n",
    "   \n",
    "    target_size = target_image_dims[0]\n",
    "    image_size = len(image)\n",
    "    padding = (image_size - target_size) // 2\n",
    "\n",
    "    return image[\n",
    "        padding:image_size - padding,\n",
    "        padding:image_size - padding,\n",
    "        :,\n",
    "    ]\n",
    "\n",
    "# for idx in range(len(test_dataset)):\n",
    "\n",
    "random_idx = random.randint(0, len(test_dataset)-1)\n",
    "image, gt_mask = test_dataset[random_idx] # image and ground truth from test dataset\n",
    "image_vis = crop_image(np.transpose(test_dataset[random_idx][0].astype('uint8'), (1, 2, 0)))\n",
    "x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "# Predict test image\n",
    "pred_mask = best_model(x_tensor)\n",
    "pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n",
    "# Convert pred_mask from `CHW` format to `HWC` format\n",
    "pred_mask = np.transpose(pred_mask,(1,2,0))\n",
    "# Get prediction channel corresponding to building\n",
    "pred_calcium_heatmap = pred_mask[:,:,class_names.index('calcium')]\n",
    "pred_mask = crop_image(colour_code_segmentation(reverse_one_hot(pred_mask), class_rgb_values))\n",
    "# Convert gt_mask from `CHW` format to `HWC` format\n",
    "gt_mask = np.transpose(gt_mask,(1,2,0))\n",
    "gt_mask = crop_image(colour_code_segmentation(reverse_one_hot(gt_mask), class_rgb_values))\n",
    "\n",
    "image_vis.shape\n",
    "\n",
    "crop_image(test_dataset[random_idx][0].astype('uint8')).shape\n",
    "\n",
    "pred_mask.shape\n",
    "\n",
    "gt_mask.shape\n",
    "\n",
    "cv2.imwrite(\n",
    "    os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), \n",
    "    np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1]\n",
    "    )    \n",
    "visualize(\n",
    "    original_image = image_vis,\n",
    "    ground_truth_mask = gt_mask,\n",
    "    predicted_mask = pred_mask,\n",
    "    predicted_building_heatmap = pred_calcium_heatmap\n",
    ")\n",
    "\n",
    "### Evaluating Test Metrics\n",
    "\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_logs = test_epoch.run(test_dataloader)\n",
    "print(\"Evaluation on Test Data: \")\n",
    "print(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\n",
    "print(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")\n",
    "\n",
    "## Label Centroids with OpenCV\n",
    "\n",
    "def find_centroids(segmented_img):\n",
    "  centroids = []\n",
    "  cont, hierarchy = cv2.findContours(segmented_img, \n",
    "                          cv2.RETR_EXTERNAL, \n",
    "                          cv2.CHAIN_APPROX_SIMPLE)\n",
    "  for c in cont:\n",
    "    # compute the center of the contour\n",
    "    M = cv2.moments(c)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    centroids.append((cX, cY))\n",
    "  \n",
    "  return centroids"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
